{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3713b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:29:57.051660Z",
     "start_time": "2023-06-19T08:29:57.046859Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# username = 'cvillarin'\n",
    "# username = 'mbalogal'\n",
    "username = 'jfabrero'\n",
    "os.environ['XDG_CACHE_HOME'] = f'/home/msds2023/{username}/.cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = f'/home/msds2023/{username}/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed757fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:29:57.058895Z",
     "start_time": "2023-06-19T08:29:57.054105Z"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/stevenstalder/NN-Explainer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91951dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:29:57.533283Z",
     "start_time": "2023-06-19T08:29:57.063247Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r \"./NN-Explainer/src/utils\" .\n",
    "!cp -r \"./NN-Explainer/src/models\" .\n",
    "!cp ./explainer_salita.py ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc5f8f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:00.715391Z",
     "start_time": "2023-06-19T08:29:57.539066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5161326e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:00.760456Z",
     "start_time": "2023-06-19T08:30:00.717509Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification, Wav2Vec2Model\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "from utils.helper import get_targets_from_annotations\n",
    "from utils.metrics import SingleLabelMetrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9180d11d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:01.652765Z",
     "start_time": "2023-06-19T08:30:00.763923Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from models.explainer import Deeplabv3Resnet50ExplainerModel\n",
    "from models.classifier import VGG16ClassifierModel, Resnet50ClassifierModel\n",
    "from utils.image_utils import save_mask, save_masked_image, save_all_class_masks\n",
    "from utils.loss import TotalVariationConv, ClassMaskAreaLoss, entropy_loss\n",
    "import pandas as pd\n",
    "import torchaudio as ta\n",
    "from torchaudio import transforms\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from pyjanitor import auto_toc\n",
    "toc = auto_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2feaf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:01.677705Z",
     "start_time": "2023-06-19T08:30:01.655356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cccb15e",
   "metadata": {},
   "source": [
    "# Dataset and LightningDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9863f45c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:01.698269Z",
     "start_time": "2023-06-19T08:30:01.680359Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, meta_data, num_frames=160_000):\n",
    "        self.num_frames = num_frames\n",
    "        self.meta_data = pd.read_csv(meta_data, header=None, index_col=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Edited\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        label_index = self._get_audio_sample_label_index(index)\n",
    "        signal, sr = ta.load(audio_sample_path, num_frames=self.num_frames)\n",
    "        transform = transforms.MelSpectrogram(sr, n_mels=40)\n",
    "        mfcc = transform(signal).squeeze()\n",
    "        \n",
    "        return mfcc, label, label_index, signal, audio_sample_path\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = self.meta_data.iloc[index, 0]\n",
    "        path = os.path.join(os.getcwd(),path)\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.meta_data.iloc[index, 1]\n",
    "    \n",
    "    def _get_audio_sample_label_index(self, index):\n",
    "        return self.meta_data.iloc[index, 2]\n",
    "    \n",
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=256, num_workers=0, pin_memory=True):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.datasets = {}\n",
    "        self.dataloaders = {}\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        stages = ['train', 'validation', 'test']\n",
    "\n",
    "        # Define your datasets\n",
    "        self.datasets = {\n",
    "            # Edited\n",
    "            x: AudioDataset(f'{x}.csv')\n",
    "            for x in stages\n",
    "        }\n",
    "\n",
    "    def pad_sequence(self, batch):\n",
    "        # Make all tensors in a batch the same length by padding with zeros\n",
    "        batch = [item.t() for item in batch]\n",
    "        batch = torch.nn.utils.rnn.pad_sequence(batch,\n",
    "                                                batch_first=True,\n",
    "                                                padding_value=0.)\n",
    "        return batch.permute(0, 2, 1)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        tensors, targets, paths = [], [], []\n",
    "\n",
    "        # Gather tensors and encode labels as indices\n",
    "        for mel, _, label_index, _, filepath in batch:\n",
    "            tensors += [mel]\n",
    "            targets += [torch.tensor(label_index)]\n",
    "            paths += [filepath]\n",
    "\n",
    "        # Group the list of tensors into a batched tensor\n",
    "        tensors = self.pad_sequence(tensors)\n",
    "        targets = torch.stack(targets)\n",
    "\n",
    "        return tensors, targets, paths\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets['train'],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets['validation'],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets['test'],\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a09d0",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2ad9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:01.717320Z",
     "start_time": "2023-06-19T08:30:01.702489Z"
    }
   },
   "outputs": [],
   "source": [
    "class SALITA(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 num_classes=14,\n",
    "                 dataset=\"lang_data\",\n",
    "                 learning_rate=1e-5,\n",
    "                 metrics_threshold=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setup_model(num_classes)\n",
    "        self.setup_losses()\n",
    "        self.setup_metrics(num_classes=num_classes)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def setup_model(self, num_classes):\n",
    "        self.conv1 = nn.Conv1d(40, 64, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, stride=1)\n",
    "        self.conv4 = nn.Conv1d(256, 512, kernel_size=3, stride=1)\n",
    "        self.conv5 = nn.Conv1d(512, 1024, kernel_size=3, stride=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1024 * 23, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Load parameters from .pth file\n",
    "        pretrained_file = \"final_model_checkpoint.pth\" \n",
    "#         pretrained_file = \"/mnt/processed/private/msds2023/cpt8/ml3_project/saves/epoch10_model.pth\" #Edited\n",
    "        if os.path.isfile(pretrained_file):\n",
    "            state_dict = torch.load(pretrained_file)\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "    def setup_losses(self):\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def setup_metrics(self, num_classes):\n",
    "        self.train_metrics = SingleLabelMetrics(num_classes=num_classes)\n",
    "        self.valid_metrics = SingleLabelMetrics(num_classes=num_classes)\n",
    "        self.test_metrics = SingleLabelMetrics(num_classes=num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        accuracy = (preds == y).sum().item() / len(y)\n",
    "\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_accuracy', accuracy)\n",
    "        self.train_metrics(logits, y)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.valid_metrics(logits, y)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        accuracy = (preds == y).sum().item() / len(y)\n",
    "\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_accuracy', accuracy)\n",
    "        self.test_metrics(logits, y)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "        \n",
    "    def on_test_epoch_end(self):\n",
    "        test_metrics = self.test_metrics.compute()\n",
    "        self.log('test_metrics', test_metrics.compute(), prog_bar=True)\n",
    "        self.test_metrics.save(model=\"classifier\", classifier_type=\"SALITA\",\n",
    "                               dataset=self.dataset)\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "        # Save the test metrics as instance attributes\n",
    "        self.test_metrics_results = test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbc731e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:01.723751Z",
     "start_time": "2023-06-19T08:30:01.719307Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "data_module = AudioDataModule(batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57cb26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:02.106461Z",
     "start_time": "2023-06-19T08:30:01.725760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SALITA(\n",
       "  (conv1): Conv1d(40, 64, kernel_size=(3,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
       "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
       "  (conv5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=23552, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=14, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (train_metrics): SingleLabelMetrics()\n",
       "  (valid_metrics): SingleLabelMetrics()\n",
       "  (test_metrics): SingleLabelMetrics()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SALITA()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6bdeed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:02.112506Z",
     "start_time": "2023-06-19T08:30:02.108640Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(''))\n",
    "except:\n",
    "#     trainer\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cf944",
   "metadata": {},
   "source": [
    "# Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0867903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:02.126330Z",
     "start_time": "2023-06-19T08:30:02.114489Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.explainer_salita import ExplainerClassifierModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46025f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:02.980885Z",
     "start_time": "2023-06-19T08:30:02.128967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "explainer = ExplainerClassifierModel(classifier=model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b698e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:02.993061Z",
     "start_time": "2023-06-19T08:30:02.983589Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExplainerClassifierModel(\n",
       "  (explainer): Deeplabv3Resnet50ExplainerModel(\n",
       "    (explainer): DeepLabV3(\n",
       "      (backbone): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): DeepLabHead(\n",
       "        (0): ASPP(\n",
       "          (convs): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (1): ASPPConv(\n",
       "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (2): ASPPConv(\n",
       "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (3): ASPPConv(\n",
       "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "            )\n",
       "            (4): ASPPPooling(\n",
       "              (0): AdaptiveAvgPool2d(output_size=1)\n",
       "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (project): Sequential(\n",
       "            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): SALITA(\n",
       "    (conv1): Conv1d(40, 64, kernel_size=(3,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
       "    (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
       "    (conv5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,))\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): Linear(in_features=23552, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=14, bias=True)\n",
       "    (loss_fn): CrossEntropyLoss()\n",
       "    (train_metrics): SingleLabelMetrics()\n",
       "    (valid_metrics): SingleLabelMetrics()\n",
       "    (test_metrics): SingleLabelMetrics()\n",
       "  )\n",
       "  (total_variation_conv): TotalVariationConv(\n",
       "    (variance_right_filter): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
       "    (variance_down_filter): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
       "  )\n",
       "  (classification_loss_fn): CrossEntropyLoss()\n",
       "  (train_metrics): SingleLabelMetrics()\n",
       "  (valid_metrics): SingleLabelMetrics()\n",
       "  (test_metrics): SingleLabelMetrics()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2ae3756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:03.020220Z",
     "start_time": "2023-06-19T08:30:02.998962Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 14\n",
    "# data_base_path = '../../datasets/'\n",
    "# data_path = Path(data_base_path) / \"lang_data\"\n",
    "data_module = AudioDataModule()\n",
    "data_module.setup(stage = \"test\")\n",
    "dataset = \"lang_data\"\n",
    "classifier_type = \"SALITA\"\n",
    "mode = \"seg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe0812c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:03.069859Z",
     "start_time": "2023-06-19T08:30:03.022727Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = Path('masks/{}_{}_{}/'.format(dataset, classifier_type, \"explainer\"))\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce1fd",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c6786c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:03.157453Z",
     "start_time": "2023-06-19T08:30:03.074272Z"
    }
   },
   "outputs": [],
   "source": [
    "i2l_dict = {\n",
    "    0.0: 'HI',\n",
    "    1.0: 'NE',\n",
    "    2.0: 'TH',\n",
    "    3.0: 'SI',\n",
    "    4.0: 'JA',\n",
    "    5.0: 'PA',\n",
    "    6.0: 'AR',\n",
    "    7.0: 'TA',\n",
    "    8.0: 'KN',\n",
    "    9.0: 'FA',\n",
    "    10.0: 'MY',\n",
    "    11.0: 'ZH',\n",
    "    12.0: 'UR',\n",
    "    13.0: 'ID',\n",
    "}\n",
    "\n",
    "l2i_dict = {y: x for x, y in i2l_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26885e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:03.955677Z",
     "start_time": "2023-06-19T08:30:03.159629Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f812ad7",
   "metadata": {},
   "source": [
    "# Samples\n",
    "## Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70756d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:04.601479Z",
     "start_time": "2023-06-19T08:30:03.960322Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_sample_path = 'Luffy_cut.wav'\n",
    "label = 'JA'\n",
    "label_index = l2i_dict[label]\n",
    "num_frames = 160_000\n",
    "n_mels = 40\n",
    "signal, sr = ta.load(audio_sample_path, num_frames=num_frames)\n",
    "transform = transforms.MelSpectrogram(sr, n_mels=n_mels)\n",
    "mfcc = transform(signal).squeeze()\n",
    "\n",
    "\n",
    "x = mfcc.repeat(3, 1, 1)\n",
    "x = x.to(device)\n",
    "y = torch.tensor(label_index).to(device)\n",
    "filename = audio_sample_path.rsplit('/', 1)[-1]\n",
    "\n",
    "_, _, mask, _, _ = explainer(x, y)\n",
    "predict = explainer.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3939939b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:04.610334Z",
     "start_time": "2023-06-19T08:30:04.604243Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sr, num_frames, title=\"Waveform\"):\n",
    "    waveform = waveform.numpy()\n",
    "    n_channels, n_frames = waveform.shape\n",
    "    if n_channels > 1:\n",
    "        waveform = waveform[:1]\n",
    "    \n",
    "    if n_frames > num_frames:\n",
    "        padded = waveform[:,:num_frames]\n",
    "    else:\n",
    "        padded = np.zeros((1, num_frames))\n",
    "        padded[:, :num_frames] = waveform\n",
    "        \n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    figure, axes = plt.subplots(1, 1, figsize=(15, 6))\n",
    "    axes.plot(time_axis, padded[0], linewidth=1, c='k')\n",
    "    axes.axis('off')\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e81c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:06.280915Z",
     "start_time": "2023-06-19T08:30:04.612143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"figures/figure1.png\" alt=\"plots\"style=\"display:block; margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <a name\"fig1\"></a>\n",
       "            <center style=\"font-size:14px;\n",
       "                      font-style:default;\">\n",
       "            <b>Figure 1.</b> MFCC Representation - Sample.\n",
       "            </center>\n",
       "            <center style=\"font-size:12px;\"><i>\n",
       "            .\n",
       "            </i></center>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "sns.heatmap(torch.log(x.view(40, 801, -1)[:, :, 0]+1e-3).cpu(),\n",
    "            cmap='PuRd',\n",
    "            cbar=False,\n",
    "            ax=ax[0])\n",
    "sns.heatmap(mask.view(40, 801, -1)[:, :, 0].cpu(),\n",
    "            cmap='gray',\n",
    "            cbar=False,\n",
    "            ax=ax[1])\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('MFCC of the Sample Audio File')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Saliency Mask of the Sample Audio File')\n",
    "toc.add_fig('MFCC Representation - Sample', width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "491d81d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:06.724815Z",
     "start_time": "2023-06-19T08:30:06.285381Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import erosion, dilation, opening, closing\n",
    "def erode(image, selem, n=1):\n",
    "    \"\"\"Perform erosion `n` times\"\"\"\n",
    "    for _ in range(n):\n",
    "        image = erosion(image, selem)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def dilate(image, selem, n=1):\n",
    "    \"\"\"Perform dilation `n` times\"\"\"\n",
    "    for _ in range(n):\n",
    "        image = dilation(image, selem)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def n_close(image, selem, n=1):\n",
    "    \"\"\"Perform dilation `n` times\"\"\"\n",
    "    for _ in range(n):\n",
    "        image = closing(image, selem)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def n_open(image, selem, n=1):\n",
    "    \"\"\"Perform dilation `n` times\"\"\"\n",
    "    for _ in range(n):\n",
    "        image = opening(image, selem)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_waveform(waveform, sr, num_frames, title=\"Waveform\"):\n",
    "    waveform = waveform.numpy()\n",
    "    n_channels, n_frames = waveform.shape\n",
    "    if n_channels > 1:\n",
    "        waveform = waveform[:1]\n",
    "    \n",
    "    if n_frames > num_frames:\n",
    "        padded = waveform[:,:num_frames]\n",
    "    else:\n",
    "        padded = np.zeros((1, num_frames))\n",
    "        padded[:, :num_frames] = waveform\n",
    "        \n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    figure, axes = plt.subplots(1, 1, figsize=(15, 6))\n",
    "    axes.plot(time_axis, padded[0], linewidth=1, c='k')\n",
    "    axes.axis('off')\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    return padded\n",
    "\n",
    "\n",
    "def colorFader(c1,c2,mix=0): #fade (linear interpolate) from color c1 (at mix=0) to c2 (mix=1)\n",
    "    c1=np.array(mpl.colors.to_rgb(c1))\n",
    "    c2=np.array(mpl.colors.to_rgb(c2))\n",
    "    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0c57cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:06.841773Z",
     "start_time": "2023-06-19T08:30:06.727158Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform, sr = ta.load(audio_sample_path)\n",
    "plot_mask = mask + mask.min()\n",
    "plot_mask = (plot_mask.sum(1) / plot_mask.sum(1).max()).mean(0)\n",
    "thick_mask = (plot_mask > plot_mask.quantile(.75)).float()\n",
    "wave_mask = plot_mask[:-1].view(1, -1).t().repeat(1, 200).view(1, -1).cpu().numpy()\n",
    "\n",
    "closed_mask = erode(thick_mask.repeat(3, 1).cpu().numpy(),\n",
    "                      np.array([[0,0,0],\n",
    "                                [1,1,1],\n",
    "                                [0,0,0]]),\n",
    "                      5)\n",
    "closed_mask = dilate(closed_mask,\n",
    "                      np.array([[0,0,0],\n",
    "                                [1,1,1],\n",
    "                                [0,0,0]]),\n",
    "                      5)\n",
    "closed_mask = n_close(closed_mask,\n",
    "                      np.array([[0,0,0],\n",
    "                                [1,1,1],\n",
    "                                [0,0,0]]),\n",
    "                      5)\n",
    "\n",
    "wave_top_mask = np.repeat(closed_mask[0, :-1].reshape(1, -1).T, 200, 1).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30eefe3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:08.802411Z",
     "start_time": "2023-06-19T08:30:06.844178Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_waveform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m time_axis \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m160_000\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ai \u001b[38;5;129;01min\u001b[39;00m ax:\n\u001b[0;32m---> 12\u001b[0m     ai\u001b[38;5;241m.\u001b[39mplot(time_axis, \u001b[43mpadded_waveform\u001b[49m[\u001b[38;5;241m0\u001b[39m], linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     ai\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Waveform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_waveform' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1='white'\n",
    "c2='purple'\n",
    "n=801\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 2))\n",
    "for i in range(n):\n",
    "    ax[1].axvline(i, color=colorFader(c1,c2,closed_mask[0, i]), linewidth=4)\n",
    "\n",
    "time_axis = torch.arange(0, 160_000) / 200\n",
    "\n",
    "for ai in ax:\n",
    "    ai.plot(time_axis, padded_waveform[0], linewidth=1, c='k')\n",
    "    ai.axis('off')\n",
    "\n",
    "ax[0].set_title('Original Waveform')\n",
    "ax[1].set_title('Waveform with Importance Gradients')\n",
    "toc.add_fig('Sample Timestep Importance Identification', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef6002",
   "metadata": {},
   "source": [
    "# Original Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2787f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:08.805007Z",
     "start_time": "2023-06-19T08:30:08.804994Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(padded_waveform, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf30961",
   "metadata": {},
   "source": [
    "# Mask Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7dc5ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:30:08.805956Z",
     "start_time": "2023-06-19T08:30:08.805943Z"
    }
   },
   "outputs": [],
   "source": [
    "Audio(padded_waveform*wave_top_mask, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4e86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
